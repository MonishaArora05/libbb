{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c394e52c-2962-4396-bca8-0a8b30965655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter item you want?\n",
      "1) dining-kitchen\n",
      "2) bags-accessories\n",
      "3) watches\n",
      " watches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sale Price: ₹ 2,000 | Product name: Chumbak Smartwatch - Wilderness | Link: https://www.chumbak.com/products/chumbak-smartwatch-wilderness\n",
      "Sale Price: ₹ 2,000 | Product name: Chumbak Smartwatch - Rainforest | Link: https://www.chumbak.com/products/chumbak-smartwatch-rainforest\n",
      "Sale Price: ₹ 2,000 | Product name: Chumbak Smartwatch for Women- Mosaic | Link: https://www.chumbak.com/products/chumbak-smartwatch-for-women\n",
      "Sale Price: ₹ 2,000 | Product name: Chumbak Smartwatch - Bloom | Link: https://www.chumbak.com/products/chumbak-smartwatch-bloom\n",
      "Total count: 179\n",
      "Select count: 4\n",
      "Page count: 2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "item = input(\"Enter item you want?\\n1) dining-kitchen\\n2) bags-accessories\\n3) watches\\n\")\n",
    "\n",
    "url = f\"https://www.chumbak.com/collections/{item}\"\n",
    "res = requests.get(url).text\n",
    "doc = BeautifulSoup(res, \"html.parser\")\n",
    "total_count = 0\n",
    "select_count = 0\n",
    "page_count = 0\n",
    "\n",
    "# Find all product-card elements\n",
    "page_text = doc.find(class_=\"pagination\")\n",
    "if page_text:\n",
    "    precise = page_text.findAll('a', class_='pagination__link')\n",
    "    if precise:\n",
    "        max_page = 0\n",
    "        for link in precise:\n",
    "            page_number = link.text.strip()\n",
    "            if page_number:  # Check if the extracted text is not empty\n",
    "                val = int(page_number)\n",
    "                if val > max_page:\n",
    "                    max_page = val\n",
    "        for page in range(1, max_page + 1):\n",
    "            page_count += 1\n",
    "            url = f\"https://www.chumbak.com/collections/{item}?page={page}\"\n",
    "            res = requests.get(url).text\n",
    "            doc = BeautifulSoup(res, \"html.parser\")\n",
    "            products = doc.find_all(class_=\"product-card\")\n",
    "            for product in products:\n",
    "                # Extract product name\n",
    "                product_name_element = product.find(class_=\"product-title\")\n",
    "                if product_name_element:\n",
    "                    product_name = product_name_element.text.strip()\n",
    "                    total_count += 1\n",
    "\n",
    "                # Extract sale price\n",
    "                sale_price_element = product.find(string=re.compile(\"₹ 2,000\"))\n",
    "                if sale_price_element:\n",
    "                    sale_price = sale_price_element.strip()\n",
    "                    select_count += 1\n",
    "\n",
    "                    # Extract product link\n",
    "                    product_link_element = product.find('a', href=True)\n",
    "                    if product_link_element:\n",
    "                        product_link = \"https://www.chumbak.com\" + product_link_element['href']\n",
    "                    else:\n",
    "                        product_link = \"Link not available\"\n",
    "\n",
    "                    # Print product details\n",
    "                    print(f\"Sale Price: {sale_price} | Product name: {product_name} | Link: {product_link}\")\n",
    "\n",
    "print(\"Total count:\", total_count)\n",
    "print(\"Select count:\", select_count)\n",
    "print(\"Page count:\", page_count)\n",
    "\n",
    "\n",
    "\n",
    "#we can also use -> sale_price_element.parent  ->sale_price_element.find_parent(\"enter name\")\n",
    "#https://www.youtube.com/watch?v=zAEfWiC_KBU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056add5-5920-4691-a99b-e99e22909769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1. **Import Modules**:  \n",
    "   The necessary libraries `requests`, `BeautifulSoup`, and `re` are imported. `requests` is used to send HTTP requests and retrieve web page content, `BeautifulSoup` is used for parsing HTML content, and `re` (regular expressions) is used to find patterns in text.\n",
    "\n",
    "2. **User Input**:  \n",
    "   The program prompts the user to choose a product category by entering one of the following options: `dining-kitchen`, `bags-accessories`, or `watches`. This input will be used to form the URL for the product collection.\n",
    "\n",
    "3. **Generate URL**:  \n",
    "   Based on the user's input, a URL is dynamically created using string formatting (`f\"...\"`). This URL points to the product collection page on Chumbak's website.\n",
    "\n",
    "4. **Request and Parse Page**:  \n",
    "   A GET request is sent to the generated URL, and the HTML content of the page is retrieved. This content is then parsed using BeautifulSoup, which transforms the raw HTML into a more manageable structure for extracting information.\n",
    "\n",
    "5. **Initialize Counters**:  \n",
    "   Three counters are initialized:\n",
    "   - `total_count`: Tracks the total number of products processed.\n",
    "   - `select_count`: Tracks the number of products that match the price condition (e.g., \"₹ 2,000\").\n",
    "   - `page_count`: Tracks the number of pages processed.\n",
    "\n",
    "6. **Find Pagination**:  \n",
    "   The program searches for the pagination section in the HTML using `doc.find(class_=\"pagination\")`. This helps identify how many pages of products exist on the website.\n",
    "\n",
    "#### Step 7: **Determine Total Pages**\n",
    "- The program checks if there is a pagination section in the HTML.\n",
    "  - It first finds the pagination element using `doc.find(class_=\"pagination\")`.\n",
    "  - If pagination exists, it extracts all links (`<a>`) within the pagination using `findAll('a', class_='pagination__link')`.\n",
    "  - For each page link, it strips the text, converts it into an integer, and updates the `max_page` variable to store the highest page number found.\n",
    "  - This ensures that the script knows the total number of pages it needs to scrape.\n",
    "\n",
    "#### Step 8: **Iterate Over Each Page**\n",
    "- The program loops through all the pages, starting from page 1 to `max_page`, which was determined in Step 7.\n",
    "  - For each page, it constructs the URL by appending the page number to the base URL using `url = f\"https://www.chumbak.com/collections/{item}?page={page}\"`.\n",
    "  - A request is made to retrieve the page’s HTML content, and this content is parsed with BeautifulSoup.\n",
    "  - The loop continues until all pages have been processed, incrementing the `page_count` each time.\n",
    "\n",
    "#### Step 9: **Find Product Details**\n",
    "- For each page, the program looks for all product cards on the page by searching for elements with the class `product-card` using `doc.find_all(class_=\"product-card\")`.\n",
    "  - This returns a list of product card elements on the page, which will be iterated through in the next step.\n",
    "  - This helps extract details for each individual product listed on the page.\n",
    "\n",
    "#### Step 10: **Extract Product Info**\n",
    "- Within each product card, the program extracts specific details:\n",
    "  1. **Product Name**: It finds the product name by looking for an element with the class `product-title`. The text is stripped to remove extra spaces.\n",
    "  2. **Sale Price**: It searches for a string that matches the price pattern (`\"₹ 2,000\"`) using regular expressions (`re.compile(\"₹ 2,000\")`).\n",
    "  3. **Product Link**: It looks for an anchor tag (`<a>`) that contains an `href` attribute. If found, it combines it with the base URL to form a full product link.\n",
    "  - If a product meets the price condition (sale price equals \"₹ 2,000\"), it stores the details and prints them.\n",
    "\n",
    "#### Step 11: **Print and Count Filtered Products**\n",
    "- If the sale price matches \"₹ 2,000\", the program:\n",
    "  1. Increments the `select_count` by 1 (for each product that matches the price condition).\n",
    "  2. Prints the sale price, product name, and product link.\n",
    "  - The program also increments the `total_count` for every product processed, regardless of whether it meets the price condition.\n",
    "\n",
    "#### Step 12: **Summary**\n",
    "- After processing all pages and products:\n",
    "  - The program prints the total number of products (`total_count`).\n",
    "  - It prints the number of products that matched the price condition (`select_count`).\n",
    "  - It prints the number of pages processed (`page_count`).\n",
    "  - These values provide an overview of the scraping process and how many relevant products were found.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
