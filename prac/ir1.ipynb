{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c81790-bc2f-40fd-8607-35da43e0d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Information Retrieval (IR) is the process of extracting relevant information from vast collections of unstructured or semi-structured data, such as documents, web pages, or databases, to satisfy a userâ€™s information need. It involves several key steps, starting with document representation, where raw text is preprocessedâ€”through tokenization, stemming, lemmatization, and stop-word removalâ€”to ensure consistency in indexing and retrieval. Next, indexing organizes data to allow efficient searching, often using inverted indexes that map terms to their occurrences across documents. Query processing transforms and refines user queries to enhance search relevance, incorporating techniques like query expansion, synonym recognition, and spelling correction. Finally, the matching and ranking stage scores and ranks documents based on relevance to the query, typically using algorithms like TF-IDF or modern deep learning models, ensuring that the most relevant results appear at the top. Together, these components enable IR systems to efficiently retrieve the most pertinent information in response to user queries.\n",
      "\n",
      "Tokenized Words:\n",
      " ['Information', 'Retrieval', '(', 'IR', ')', 'is', 'the', 'process', 'of', 'extracting', 'relevant', 'information', 'from', 'vast', 'collections', 'of', 'unstructured', 'or', 'semi-structured', 'data', ',', 'such', 'as', 'documents', ',', 'web', 'pages', ',', 'or', 'databases', ',', 'to', 'satisfy', 'a', 'userâ€™s', 'information', 'need', '.', 'It', 'involves', 'several', 'key', 'steps', ',', 'starting', 'with', 'document', 'representation', ',', 'where', 'raw', 'text', 'is', 'preprocessedâ€', '”', 'through', 'tokenization', ',', 'stemming', ',', 'lemmatization', ',', 'and', 'stop-word', 'removalâ€', '”', 'to', 'ensure', 'consistency', 'in', 'indexing', 'and', 'retrieval', '.', 'Next', ',', 'indexing', 'organizes', 'data', 'to', 'allow', 'efficient', 'searching', ',', 'often', 'using', 'inverted', 'indexes', 'that', 'map', 'terms', 'to', 'their', 'occurrences', 'across', 'documents', '.', 'Query', 'processing', 'transforms', 'and', 'refines', 'user', 'queries', 'to', 'enhance', 'search', 'relevance', ',', 'incorporating', 'techniques', 'like', 'query', 'expansion', ',', 'synonym', 'recognition', ',', 'and', 'spelling', 'correction', '.', 'Finally', ',', 'the', 'matching', 'and', 'ranking', 'stage', 'scores', 'and', 'ranks', 'documents', 'based', 'on', 'relevance', 'to', 'the', 'query', ',', 'typically', 'using', 'algorithms', 'like', 'TF-IDF', 'or', 'modern', 'deep', 'learning', 'models', ',', 'ensuring', 'that', 'the', 'most', 'relevant', 'results', 'appear', 'at', 'the', 'top', '.', 'Together', ',', 'these', 'components', 'enable', 'IR', 'systems', 'to', 'efficiently', 'retrieve', 'the', 'most', 'pertinent', 'information', 'in', 'response', 'to', 'user', 'queries', '.']\n",
      "\n",
      "After Removing Punctuation:\n",
      " ['Information', 'Retrieval', 'IR', 'is', 'the', 'process', 'of', 'extracting', 'relevant', 'information', 'from', 'vast', 'collections', 'of', 'unstructured', 'or', 'semi-structured', 'data', 'such', 'as', 'documents', 'web', 'pages', 'or', 'databases', 'to', 'satisfy', 'a', 'userâ€™s', 'information', 'need', 'It', 'involves', 'several', 'key', 'steps', 'starting', 'with', 'document', 'representation', 'where', 'raw', 'text', 'is', 'preprocessedâ€', '”', 'through', 'tokenization', 'stemming', 'lemmatization', 'and', 'stop-word', 'removalâ€', '”', 'to', 'ensure', 'consistency', 'in', 'indexing', 'and', 'retrieval', 'Next', 'indexing', 'organizes', 'data', 'to', 'allow', 'efficient', 'searching', 'often', 'using', 'inverted', 'indexes', 'that', 'map', 'terms', 'to', 'their', 'occurrences', 'across', 'documents', 'Query', 'processing', 'transforms', 'and', 'refines', 'user', 'queries', 'to', 'enhance', 'search', 'relevance', 'incorporating', 'techniques', 'like', 'query', 'expansion', 'synonym', 'recognition', 'and', 'spelling', 'correction', 'Finally', 'the', 'matching', 'and', 'ranking', 'stage', 'scores', 'and', 'ranks', 'documents', 'based', 'on', 'relevance', 'to', 'the', 'query', 'typically', 'using', 'algorithms', 'like', 'TF-IDF', 'or', 'modern', 'deep', 'learning', 'models', 'ensuring', 'that', 'the', 'most', 'relevant', 'results', 'appear', 'at', 'the', 'top', 'Together', 'these', 'components', 'enable', 'IR', 'systems', 'to', 'efficiently', 'retrieve', 'the', 'most', 'pertinent', 'information', 'in', 'response', 'to', 'user', 'queries']\n",
      "\n",
      "After Removing Stopwords:\n",
      " ['Information', 'Retrieval', 'IR', 'process', 'extracting', 'relevant', 'information', 'vast', 'collections', 'unstructured', 'semi-structured', 'data', 'documents', 'web', 'pages', 'databases', 'satisfy', 'userâ€™s', 'information', 'need', 'involves', 'several', 'key', 'steps', 'starting', 'document', 'representation', 'raw', 'text', 'preprocessedâ€', '”', 'tokenization', 'stemming', 'lemmatization', 'stop-word', 'removalâ€', '”', 'ensure', 'consistency', 'indexing', 'retrieval', 'Next', 'indexing', 'organizes', 'data', 'allow', 'efficient', 'searching', 'often', 'using', 'inverted', 'indexes', 'map', 'terms', 'occurrences', 'across', 'documents', 'Query', 'processing', 'transforms', 'refines', 'user', 'queries', 'enhance', 'search', 'relevance', 'incorporating', 'techniques', 'like', 'query', 'expansion', 'synonym', 'recognition', 'spelling', 'correction', 'Finally', 'matching', 'ranking', 'stage', 'scores', 'ranks', 'documents', 'based', 'relevance', 'query', 'typically', 'using', 'algorithms', 'like', 'TF-IDF', 'modern', 'deep', 'learning', 'models', 'ensuring', 'relevant', 'results', 'appear', 'top', 'Together', 'components', 'enable', 'IR', 'systems', 'efficiently', 'retrieve', 'pertinent', 'information', 'response', 'user', 'queries']\n",
      "\n",
      "After Stemming:\n",
      " ['inform', 'retriev', 'ir', 'process', 'extract', 'relev', 'inform', 'vast', 'collect', 'unstructur', 'semi-structur', 'data', 'document', 'web', 'page', 'databas', 'satisfi', 'userâ€™', 'inform', 'need', 'involv', 'sever', 'key', 'step', 'start', 'document', 'represent', 'raw', 'text', 'preprocessedâ€', '”', 'token', 'stem', 'lemmat', 'stop-word', 'removalâ€', '”', 'ensur', 'consist', 'index', 'retriev', 'next', 'index', 'organ', 'data', 'allow', 'effici', 'search', 'often', 'use', 'invert', 'index', 'map', 'term', 'occurr', 'across', 'document', 'queri', 'process', 'transform', 'refin', 'user', 'queri', 'enhanc', 'search', 'relev', 'incorpor', 'techniqu', 'like', 'queri', 'expans', 'synonym', 'recognit', 'spell', 'correct', 'final', 'match', 'rank', 'stage', 'score', 'rank', 'document', 'base', 'relev', 'queri', 'typic', 'use', 'algorithm', 'like', 'tf-idf', 'modern', 'deep', 'learn', 'model', 'ensur', 'relev', 'result', 'appear', 'top', 'togeth', 'compon', 'enabl', 'ir', 'system', 'effici', 'retriev', 'pertin', 'inform', 'respons', 'user', 'queri']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Read text from file\n",
    "text = \"\"\n",
    "with open(\"IR_text.txt\") as file:\n",
    "    for line in file:\n",
    "        text += line\n",
    "print(\"Original Text:\\n\", text)\n",
    "\n",
    "# Tokenize the text\n",
    "word_token = word_tokenize(text)\n",
    "print(\"\\nTokenized Words:\\n\", word_token)\n",
    "\n",
    "# Remove punctuation\n",
    "def remove(words):\n",
    "    cleaned_words = [word for word in words if word not in string.punctuation]\n",
    "    return cleaned_words\n",
    "\n",
    "clean = remove(word_token)\n",
    "print(\"\\nAfter Removing Punctuation:\\n\", clean)\n",
    "\n",
    "# Remove stopwords\n",
    "swords = stopwords.words(\"english\")\n",
    "def remove_stopwords(clean_words):\n",
    "    without_stop = [word for word in clean_words if word.lower() not in swords]\n",
    "    return without_stop\n",
    "\n",
    "removed = remove_stopwords(clean)\n",
    "print(\"\\nAfter Removing Stopwords:\\n\", removed)\n",
    "\n",
    "# Apply stemming\n",
    "def stemming(cleaned):\n",
    "    stemmed_words = [ps.stem(word) for word in cleaned]\n",
    "    return stemmed_words\n",
    "\n",
    "stemmed = stemming(removed)\n",
    "print(\"\\nAfter Stemming:\\n\", stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d70db-3772-46b5-bf2f-fa33f0a50a2f",
   "metadata": {},
   "source": [
    "Here's a summary of each step in the code:\n",
    "\n",
    "1. **Reading the Text:**\n",
    "   - The program reads the content of a file called `IR_text.txt` line by line and combines all the lines into one string.\n",
    "   - **Purpose:** This step loads the raw text data for further processing.\n",
    "\n",
    "2. **Tokenizing the Text:**\n",
    "   - The `word_tokenize()` function from NLTK is used to split the text into individual words (tokens).\n",
    "   - **Purpose:** Tokenization is the process of breaking down text into smaller pieces (words), which are easier to analyze.\n",
    "\n",
    "3. **Removing Punctuation:**\n",
    "   - A function `remove()` filters out punctuation marks using Python's `string.punctuation`.\n",
    "   - **Purpose:** To clean the text by removing unnecessary punctuation, leaving only words for analysis.\n",
    "\n",
    "4. **Removing Stopwords:**\n",
    "   - The program uses NLTK's list of stopwords (common, non-informative words like \"the\", \"is\", etc.) and removes them from the token list.\n",
    "   - **Purpose:** Stopwords are often removed because they do not contribute significant meaning to text analysis.\n",
    "\n",
    "5. **Stemming:**\n",
    "   - The `PorterStemmer` is used to reduce words to their root forms (e.g., \"running\" becomes \"run\").\n",
    "   - **Purpose:** Stemming simplifies words to their base or root form, helping in grouping similar words (e.g., \"running\" and \"runner\" both become \"run\").\n",
    "\n",
    "Each step cleans, transforms, and prepares the text for analysis by breaking it down into more manageable and meaningful components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806e24a-842c-462c-a45e-18468e04c30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
